---
title: "Factors Influencing Ride-Sharing Pricing in Boston: A Study on Lyft and Uber"
author:
- name: Jianjun Gao
- name: Aaron Yang
- name: Luhuan Wang
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    number_sections: no
    fig_caption: yes
    df_print: paged
    css: "apa-style.css"
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
affiliation: George Washington University
advisor: Dr. Mohamed Shabani Kariburyo
subtitle: DATS_6101_Midterm_Project_Summary_Paper
shorttitle: "Ride-Sharing Pricing in Boston"
---


# 1. Introduction

Exploring the factors influencing ride-sharing pricing, particularly in the context of Boston's Uber and Lyft services, is crucial. This investigation offers insights into the dynamic pricing strategies of these prominent ride-sharing companies. Understanding these factors is not only beneficial for consumers seeking cost-effective transportation options but also for the companies themselves in optimizing their pricing models in a highly competitive market.

A pertinent study conducted on the ride-share market in Boston focused on analyzing Uber vs. Lyft. This research delved into the pricing strategies of these companies, examining a multitude of factors such as weather conditions, traffic, and special events, and how they impact pricing. The findings revealed notable differences in the pricing models of Uber and Lyft, influenced by various external and internal factors, providing an enlightening perspective on ride-sharing economics in urban areas (NYC Data Science Academy, n.d.)[2].

In our mid-term project, we analyzed a dataset comprising factors like "hour", "price", "surge_multiplier", "cab_type", and "name", with 6,000 entries in each category. Our analysis revealed significant correlations, particularly between ride distance, peak-hour passenger surge multipliers, and pricing. We found that longer distances and higher passenger numbers during peak hours tend to increase prices. Conversely, the time of day showed a weaker correlation with pricing. Additionally, a notable relationship was observed between cab companies and types, suggesting that different service models and vehicle types significantly influence pricing strategies. This study provided a foundational understanding of the elements affecting ride-sharing prices in Boston.

For the final project, we have expanded our scope by utilizing a more extensive dataset containing 637,976 rows and 57 columns, sourced from https://www.kaggle.com/datasets/brllrb/uber-and-lyft-dataset-boston-ma/data[1]. This larger dataset allows for a more comprehensive analysis, incorporating a wider range of variables. We have also explored various advanced modeling techniques to deepen our understanding of the complex dynamics governing ride-sharing pricing in Boston.

The next sections of our paper will bridge the gap between our mid-term and final projects, highlighting the advancements and new insights gained. Following this, we will conduct an extensive Exploratory Data Analysis (EDA) of the expanded dataset, which will be succeeded by sophisticated modeling techniques to unravel the intricacies of ride-sharing pricing. The final section will synthesize our findings, offering conclusive insights and potential directions for future research in this domain.

# 2. The Gap between Mid-term and Final project


# 3. Exploratory Data Analysis

```{r, include=F,error=TRUE}
# Loading the libraries.
library(papaja)
library(ggplot2)
library(ezids)
library(gplots)
library(dplyr)
library(plotly)
library(corrplot)
library(lubridate)
library(caTools)
library(tm)
library(irlba)
library(text2vec)
library(recipes)
library(yardstick)
library(pls)
library(tree)
library(rmarkdown)
```

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
```

## 3.1 Dataset Overview 

The dataset contains 693,071 records and 57 variables, capturing various aspects of ride-hailing services. The data includes hour, destination, location coordinates, pricing, distance, and weather conditions among other variables.

## 3.2 Smart Questions

1. Is there any relationship between price and hour?

2. Is there any other factors to affect the final price of Uber and Lyft?

3. Do the weather factors, like temperature, wind, and sunset affect the final price?

## 3.2 Data Describe



## 3.3 Data Clearning and Preprocessing

## 3.4 Data Visulazition

## 3.5 Hypothesis Testing

## 3.6 Summary

# 4. Modeling

## 4.1 Linear Model

## 4.2 PCR Model

## 4.3 Tree Model

# 5 Conclusion



## Select Data


## Loading the Data from Csv File

```{r, results='markup', echo=TRUE}
df <- data.frame(read.csv('rideshare_kaggle.csv'))
head(df)
```
## Data EDA
**Get summary from the data**


```{r, results='markup', echo=TRUE}
summary(df) # descriptive stats
sum(is.na(df)) # check null values
# Drop NA values
df <- na.omit(df)

```
**Alter column names**


```{r, results='markup', echo=TRUE}
#alter col names
colnames(df)[colnames(df) == "cab_type"] <- "cab_company"
colnames(df)[colnames(df) == "name"] <- "cab_type"
head(df)
```

**Check for unique values in catgorial columns**

For cab_company, we can see there are 2 unique values.
```{r, results='markup', echo=TRUE}
unique(df$cab_company) #see unique values in company
```

For cab_type, we can see there are 12 unique values.
```{r, results='markup', echo=TRUE}
unique(df$cab_type) #see unique values in cab_type
```

```{r, results='markup', echo=TRUE}
# Categorical boxplot
ggplot(df, aes(x = destination, y = price, fill = cab_company)) +
  geom_boxplot() +
  theme_minimal(base_size = 18)
```

## Data Visualization
**Hour vs Mean_Price**





```{r, results='markup', echo=TRUE}

# Extract relevant columns from 'data' into 'cab_data'
cab_data <- df[c("hour", "price", "cab_company")]

# Filter the data for each company
uber_data <- cab_data[cab_data$cab_company == 'Uber',]
lyft_data <- cab_data[cab_data$cab_company == 'Lyft',]

# Plot for Uber
ggplot(data = uber_data, aes(x = hour, y = price)) + 
  geom_line(aes(group = 1), colour = "blue") + 
  geom_point(aes(color = hour)) +
  labs(title = "Hourly Uber Prices", x = "Hour", y = "Price") +
  theme_minimal()

# Plot for Lyft
ggplot(data = lyft_data, aes(x = hour, y = price)) + 
  geom_line(aes(group = 1), colour = "red") + 
  geom_point(aes(color = hour)) +
  labs(title = "Hourly Lyft Prices", x = "Hour", y = "Price") +
  theme_minimal()

# Combined plot 
ggplot(data = cab_data, aes(x = hour, y = price, color = cab_company, group = cab_company)) + 
  geom_line() + 
  geom_point(aes(shape = cab_company)) +
  labs(title = "Hourly Uber vs Lyft Prices", x = "Hour", y = "Price") +
  scale_color_manual(values = c("blue", "red")) +
  theme_minimal()
```







**Company vs price**



```{r, results='markup', echo=TRUE}
# Create a figure with two subplots
par(mfrow=c(1, 2), mar=c(5, 4, 4, 2))  # 1 row, 2 columns

# Plot histograms by cab_type for Lyft
hist(df$price[df$cab_company == "Lyft"], col="orange", xlab="Price", ylab="Frequency", main="Histogram of Prices by Cab Company (Lyft)")

# Plot histograms by cab_type for Uber
hist(df$price[df$cab_company == "Uber"], col="blue", xlab="Price", ylab="Frequency", main="Histogram of Prices by Cab Company (Uber)")

# Add legend to the figure
legend("topright", legend=c("Uber", "Lyft"), fill=c("blue", "orange"))
```




**Cab types vs Price**


```{r, results='markup', echo=TRUE}
df_lyft <- df[df$cab_company == "Lyft",]
df_uber <- df[df$cab_company == "Uber",]

# Combine the data for Lyft and Uber
df_combined <- rbind(df_lyft, df_uber)

# Calculate the median price for each cab type and order them
median_prices <- df_combined %>%
  group_by(cab_type) %>%
  summarize(median_price = median(price)) %>%
  arrange(desc(median_price))

# Reorder the levels of the cab_type factor based on median price
df_combined$cab_type <- factor(df_combined$cab_type, levels = median_prices$cab_type)

# Create a ggplot object for both Lyft and Uber with cab_type reordered
p_combined <- ggplot(df_combined, aes(x = cab_type, y = price, fill = cab_company)) +
  geom_boxplot(width = 0.5, outlier.shape = 1, outlier.size = 2, fatten = 0.5) +  # Adjust outlier size and line thickness
  labs(x = "Cab Type", y = "Price", title = "Boxplot of Prices by Cab Type (Ordered by Median Price)") +
  scale_fill_manual(values = c("Lyft" = "blue", "Uber" = "red")) +  # Set custom colors
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5),
    plot.margin = unit(c(1, 2, 1, 1), "cm")
  )

# Print the combined plot with modified aesthetics
p_combined


```




**Distance vs Price**



```{r, results='markup', echo=TRUE}
# Scatter plot: Examine the relationship between price and distance
ggplot(df, aes(x = distance, y = price)) +
  geom_point(aes(color = price), alpha = 0.5) +    # Use color to represent the value of price and set point transparency to 0.5
  labs(title = "The Plot of Price vs. Distance",    # Chart title
       x = "Distance",                              # x-axis title
       y = "Price",                                 # y-axis title
       color = "Price Value") +                     # Legend title
  theme_minimal()                                   # Use a minimalistic theme
```



**Surge_multiplier vs Price**



```{r, results='markup', echo=TRUE}
# Box plot: Examine the distribution of price across different surge multipliers
ggplot(df, aes(x = factor(surge_multiplier), y = price)) +  # Convert surge_multiplier to factor for a clearer plot
  geom_boxplot(aes(fill = factor(surge_multiplier))) +        # Fill boxes with colors based on surge_multiplier
  labs(title = "Boxplot of Price across Different Surge Multipliers",
       x = "Surge Multiplier",
       y = "Price",
       fill = "Surge Multiplier Categories") +
  theme_minimal()
```




**Plot a 3D scatter plot with arguements hour, distance, price**



```{r, results='markup', echo=TRUE}
# Create a 3D scatter plot
plot_ly(data = df, x = ~hour, y = ~distance, z = ~price, type = "scatter3d", mode = "markers", marker = list(size = 1)) %>%
  layout(scene = list(xaxis = list(title = "Hour"), yaxis = list(title = "Distance"), zaxis = list(title = "Price")))

```




## Description Statistics



**Show standard deviations**

```{r, results='markup', echo=TRUE}
# measure of variance
sd(df$price)
sd(df$distance)
sd(df$surge_multiplier)
```

**Test normality**

For hour
```{r, results='markup', echo=TRUE}
# Create a histogram
hist(df$hour)

# Create a Q-Q plot
qqnorm(df$hour)
qqline(df$hour)

# Create a density plot
plot(density(df$hour))
```

For price

```{r, results='markup', echo=TRUE}
# Create a histogram
hist(df$price)

# Create a Q-Q plot
qqnorm(df$price)
qqline(df$price)
plot(density(df$price))
```

For distance

```{r, results='markup', echo=TRUE}
# Create a histogram
hist(df$distance)

# Create a Q-Q plot
qqnorm(df$distance)
qqline(df$distance)
plot(density(df$distance))
```

For surge_multiplier

```{r, results='markup', echo=TRUE}
# Create a histogram
hist(df$surge_multiplier)

# Create a Q-Q plot
qqnorm(df$surge_multiplier)
qqline(df$surge_multiplier)
plot(density(df$surge_multiplier))
```

## Correlation Heatmap for Numeric Colmns



```{r, results='markup', echo=TRUE}
# Correlation heatmap
numeric_df <- select_if(df, is.numeric)
corr_all <- cor(numeric_df)
heatmap.2(corr_all, 
          main = "Correlation Heatmap",  # title
          key = TRUE,  # show color
          density.info = "none",  # prevent duplicate color
          trace = "none",  # prevent trace
          cellnote = round(corr_all, 2),  # show cor
          notecol = "black",  # color for cor
          margins = c(3, 3),  # set margins
          col = colorRampPalette(c("blue", "white", "red"))(100)  # set color
)
```




## Chi-Squared Test for Cab_company & Cab_type



```{r, results='markup', echo=TRUE}
# Chi-squared test
chisq_result <- chisq.test(df$cab_company, df$cab_type)

chisq_result
```





# Linear Regression Analysis for distance & surge_multiplier & hour

Finally, we chose linear regression analysis to explore the relationship between the three independent variables distance, surge_multiplier and hour and price.

We will explore whether distance, surge_multiplier and time have a linear relationship with price, and how these independent variables explain price changes.

Linear regression analysis will help us quantify the extent to which these factors affect prices.

```{r, results='markup', echo=TRUE}
#linear regression analysis
linear_model <- lm(price~distance + surge_multiplier,data = df)
summary(linear_model)
```

This is the result of a set of linear regression analysis used to explore the relationship between price, distance and surge_multiplier.

A regression model is used to predict prices using distance and doubling of the number of passengers during peak hours as independent variables.

Coefficient estimate:
Intercept's estimated value is -12.9730.

The coefficient estimate for distance is 2.8232, indicating that each unit increase in distance will cause the price to increase by approximately 2.8232 units.

The coefficient estimate for surge_multiplier is 22.8997, indicating that each unit multiplier will cause the price to increase by approximately 22.8997 units.

The p-value is less than 2e-16 (close to zero). This means that all independent variables explain prices in a statistically significant way.

Residuals statistics show the fit of the model, including minimum value, quartile, median and maximum value.
The standard deviation of the residuals is 8.52, which indicates the dispersion of the model's residuals.

Model explainability:
The Multiple R-squared is 0.184, indicating that the model can explain 18.4% of the price variation.

The Adjusted R-squared is 0.183, which takes into account the degree of freedom of the model and also illustrates the explanatory ability of the model.

The F statistic is 674 and the degrees of freedom are 2 and 5997. The p-value is also close to zero (<2e-16), indicating that the model is statistically significant overall.

The results of this linear regression analysis show:
There is a significant linear relationship between distance and the doubling of peak-hour passenger numbers and price.
The positive coefficient for distance indicates that as distance increases, price increases.

A positive coefficient for doubling the number of passengers during peak hours indicates that doubling peak hours significantly increases prices.

The overall model is statistically significant, indicating that the independent variables explain the price significantly.

```{r, results='markup', echo=TRUE}
# Convert timestamp to datetime and extract the weekday
df$timestamp <- as.POSIXct(df$timestamp, format="%Y-%m-%d %H:%M:%S", tz="UTC")
df$weekday <- weekdays(df$timestamp)

# Select the columns you need
X <- df %>% select(weekday, hour, cab_type, cab_company, distance, surge_multiplier, icon, long_summary, short_summary, destination)
y <- df$price

# Split the data into training and testing sets
set.seed(42)  # For reproducibility
split <- sample.split(y, SplitRatio = 0.7)
X_train <- subset(X, split == TRUE)
X_test <- subset(X, split == FALSE)
y_train <- subset(y, split == TRUE)
y_test <- subset(y, split == FALSE)

```

```{r, results='markup', echo=TRUE}
# Convert text feature to Corpus
corpus_train <- Corpus(VectorSource(X_train$long_summary))
corpus_test <- Corpus(VectorSource(X_test$long_summary))

# Create a document-term matrix for TF-IDF
dtm_train <- DocumentTermMatrix(corpus_train)
dtm_test <- DocumentTermMatrix(corpus_test, control = list(dictionary = Terms(dtm_train)))

# Apply TF-IDF weighting
tfidf_train <- weightTfIdf(dtm_train)
tfidf_test <- weightTfIdf(dtm_test)

# Convert to matrix
mat_train <- as.matrix(tfidf_train)
mat_test <- as.matrix(tfidf_test)

# Apply Truncated SVD
svd_train <- irlba(mat_train, nv = 10)
svd_test <- irlba(mat_test, nv = 10)

# Create data frames from SVD output
text_train <- as.data.frame(svd_train$u)
names(text_train) <- paste("text", seq(1, ncol(text_train)), sep = "")

text_test <- as.data.frame(svd_test$u)
names(text_test) <- paste("text", seq(1, ncol(text_test)), sep = "")

# Reset index before merging - in R, we can directly merge
X_train <- cbind(X_train, text_train)
X_test <- cbind(X_test, text_test)

# Drop the original 'long_summary' column
X_train$long_summary <- NULL
X_test$long_summary <- NULL

```

```{r, results='markup', echo=TRUE}

# Define the mapping as a named vector in R
ordinal_enc <- c('Shared' = 1, 'UberPool' = 1, 'Lyft' = 2, 'UberX' = 3, 'WAV' = 3,
                 'UberXL' = 4, 'Lyft XL' = 4, 'Lux' = 5, 'Lux Black' = 6, 'Black' = 6,
                 'Lux Black XL' = 7, 'Black SUV' = 7)

# Replace the 'name' column in X_train and X_test with the mapped values
X_train <- X_train %>% 
  mutate(cab_type = recode(cab_type, !!!ordinal_enc))

X_test <- X_test %>% 
  mutate(cab_type = recode(cab_type, !!!ordinal_enc))

```

```{r, results='markup', echo=TRUE}
# Preprocessing for categorical variables
rec <- recipe(~ ., data = X_train) %>%
      step_dummy(all_nominal(), -all_outcomes())

# Prepare and bake the recipe
prep_rec <- prep(rec, training = X_train)
X_train_processed <- bake(prep_rec, X_train)
X_test_processed <- bake(prep_rec, X_test)
```

```{r, results='markup', echo=TRUE}
# Linear Regression
linear_model <- lm(y_train ~ ., data = X_train_processed)
summary(linear_model)

```

```{r, results='markup', echo=TRUE}
pcr_model <- pcr(y_train ~ ., data = X_train_processed, scale = TRUE, validation = "CV")
summary(pcr_model)
```



```{r, results='markup', echo=TRUE}
# Tree Analysis
tree_model <- tree(y_train ~ ., data = X_train_processed)

# Summary of the tree model
summary(tree_model)

# Plot the tree
plot(tree_model)
text(tree_model, pretty = 0)
```
# Summary 

In this study, we chose a data set consisting of five vertical columns "hour", "price", "surge_multiplier", "cab_type" and "name" and 6,000 data in each vertical column. These factors can effectively help us analyze the reasons for price changes of online ride-hailing companies. Of course, there are limitations in this set of datasets. The huge data in the original dataset forces us to use python to cut the data to make this dataset suitable for our research. After completing the collection and production of the dataset, we can use EDA to efficiently find the answers we need. Moreover, if more information about weekdays, holidays or weather conditions could be collected, then these might be more helpful in predicting price.
In our data analysis, we looked at the relationship between Uber and Lyft prices and different factors. Our results show that there is a strong correlation between distance and the surge_multiplier in the number of passengers during peak hours and price. In particular, distance and the doubling of passenger numbers during peak hours can largely explain changes in prices. This means that longer distances and doubling the number of passengers during peak times tend to lead to higher prices, which are key factors for both passengers and drivers.

In contrast, the time factor (hours) does not have a strong explanatory power on prices. Our analysis found that the correlation between time and price is relatively weak, and even if we try to exclude the impact of time factors on price, there is no significant change. This may indicate that time is not the main factor in determining price.

Furthermore, we observe a linear relationship between distance, doubling of peak-hour passenger numbers, and price, meaning that changes in price can be explained by a linear combination of these factors.

In our research, we also found a strong correlation between "Cab_company" and "Cab_type". This may be because Uber and Lyft's pricing strategies relate to different Cab_companies and car models. Especially "Cab_type" as a string type variable, we did not study it in depth, but we think that in future research, it may become an important factor, because different types of cars may have a significant impact on the price.

Overall, our study provides useful insights into the factors that drive Uber and Lyft prices, highlights the importance of distance and peak-hour ridership doubling, and points to some potential research directions such as different cabs The impact of company and model on price. These results contribute to a better understanding of price-setting strategies for shared mobility services, providing more information and insights to passengers and drivers.


# Reference Page

1.Brllrb. (2019). Uber and Lyft Dataset: Boston, MA. Kaggle. https://www.kaggle.com/datasets/brllrb/uber-and-lyft-dataset-boston-ma/data.
2.NYC Data Science Academy. (n.d.). Uber vs. Lyft: A Data Analysis of the Rideshare Market in Boston. Retrieved from https://nycdatascience.com/blog/student-works/uber-vs-lyft-a-data-analysis-of-the-rideshare-market-in-boston/.
